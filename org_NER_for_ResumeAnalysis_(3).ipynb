{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bluevit/Recruit-Right-Precision-Hiring-with-AI-Insight/blob/master/org_NER_for_ResumeAnalysis_(3).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRF5YRktW07P"
      },
      "source": [
        "<h3>Training spaCy NER for Resume Analysis</h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOYpCT9v9RBd",
        "outputId": "a43a65a8-5515-4995-e373-05b938866616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy #==1.25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv_CRv5cm7Hx",
        "outputId": "7d340ab6-0ec3-4451-c18a-1067ec85e499"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.4)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.8.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.0)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading spacy-3.8.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: spacy\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.8.4\n",
            "    Uninstalling spacy-3.8.4:\n",
            "      Successfully uninstalled spacy-3.8.4\n",
            "Successfully installed spacy-3.8.5\n",
            "Collecting spacy-transformers\n",
            "  Downloading spacy_transformers-1.3.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: spacy<4.1.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from spacy-transformers) (3.8.5)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy-transformers) (2.0.2)\n",
            "Collecting transformers<4.50.0,>=3.4.0 (from spacy-transformers)\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m162.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from spacy-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from spacy-transformers) (2.5.1)\n",
            "Collecting spacy-alignments<1.0.0,>=0.7.2 (from spacy-transformers)\n",
            "  Downloading spacy_alignments-0.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (1.1.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.11.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->spacy-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->spacy-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->spacy-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->spacy-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->spacy-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->spacy-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->spacy-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->spacy-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->spacy-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->spacy-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->spacy-transformers) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers) (0.29.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers) (0.5.3)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4.1.0,>=3.5.0->spacy-transformers) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<4.1.0,>=3.5.0->spacy-transformers) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.1.2)\n",
            "Downloading spacy_transformers-1.3.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (756 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.2/756.2 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spacy_alignments-0.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.0/314.0 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: spacy-alignments, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, transformers, spacy-transformers\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.50.2\n",
            "    Uninstalling transformers-4.50.2:\n",
            "      Successfully uninstalled transformers-4.50.2\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 spacy-alignments-0.9.1 spacy-transformers-1.3.8 transformers-4.49.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U spacy #==3.7.2\n",
        "!pip install spacy-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgpoPgHMnl1F"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOytCEpK13eM",
        "outputId": "e2fe627d-d633-4e99-f6c1-b1674e9431e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.0)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-trf==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.8.0/en_core_web_trf-3.8.0-py3-none-any.whl (457.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.4/457.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy-curated-transformers<1.0.0,>=0.2.2 (from en-core-web-trf==3.8.0)\n",
            "  Downloading spacy_curated_transformers-0.3.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting curated-transformers<0.2.0,>=0.1.0 (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
            "  Downloading curated_transformers-0.1.1-py2.py3-none-any.whl.metadata (965 bytes)\n",
            "Collecting curated-tokenizers<0.1.0,>=0.0.9 (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
            "  Downloading curated_tokenizers-0.0.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: regex>=2022 in /usr/local/lib/python3.11/dist-packages (from curated-tokenizers<0.1.0,>=0.0.9->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2024.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.0.2)\n",
            "Downloading spacy_curated_transformers-0.3.0-py2.py3-none-any.whl (236 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.3/236.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading curated_tokenizers-0.0.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (735 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m735.6/735.6 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading curated_transformers-0.1.1-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: curated-tokenizers, curated-transformers, spacy-curated-transformers, en-core-web-trf\n",
            "Successfully installed curated-tokenizers-0.0.9 curated-transformers-0.1.1 en-core-web-trf-3.8.0 spacy-curated-transformers-0.3.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_trf')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_trf  # Download Transformer-based model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPitVvbJ2EV0",
        "outputId": "d885a18f-fe47-4b29-e0b2-36c84ecef64d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Config file created successfully!\n"
          ]
        }
      ],
      "source": [
        "config_text = \"\"\"[paths]\n",
        "train = \"./train_data.spacy\"\n",
        "dev = \"./dev_data.spacy\"\n",
        "vectors = null\n",
        "\n",
        "[system]\n",
        "gpu_allocator = \"pytorch\"\n",
        "\n",
        "[nlp]\n",
        "lang = \"en\"\n",
        "pipeline = [\"transformer\", \"ner\"]\n",
        "batch_size = 8\n",
        "\n",
        "[components]\n",
        "[components.ner]\n",
        "factory = \"ner\"\n",
        "\n",
        "[components.transformer]\n",
        "factory = \"transformer\"\n",
        "\n",
        "[training]\n",
        "optimizer = \"Adam\"\n",
        "dropout = 0.2\n",
        "patience = 5\n",
        "max_epochs = 20\n",
        "batch_size = 8\n",
        "\n",
        "[training.optimizer]\n",
        "@optimizers = \"Adam\"\n",
        "learn_rate = 0.00005\n",
        "\"\"\"\n",
        "\n",
        "with open(\"config.cfg\", \"w\") as f:\n",
        "    f.write(config_text)\n",
        "\n",
        "print(\"✅ Config file created successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap7YCy2E2HEG",
        "outputId": "5ed2792e-7df2-45a1-ae02-49186477540d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[paths]\n",
            "train = \"./train_data.spacy\"\n",
            "dev = \"./dev_data.spacy\"\n",
            "vectors = null\n",
            "\n",
            "[system]\n",
            "gpu_allocator = \"pytorch\"\n",
            "\n",
            "[nlp]\n",
            "lang = \"en\"\n",
            "pipeline = [\"transformer\", \"ner\"]\n",
            "batch_size = 8\n",
            "\n",
            "[components]\n",
            "[components.ner]\n",
            "factory = \"ner\"\n",
            "\n",
            "[components.transformer]\n",
            "factory = \"transformer\"\n",
            "\n",
            "[training]\n",
            "optimizer = \"Adam\"\n",
            "dropout = 0.2\n",
            "patience = 5\n",
            "max_epochs = 20\n",
            "batch_size = 8\n",
            "\n",
            "[training.optimizer]\n",
            "@optimizers = \"Adam\"\n",
            "learn_rate = 0.00005\n"
          ]
        }
      ],
      "source": [
        "!cat config.cfg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glaUB9zsolEf",
        "outputId": "18f95463-19fa-4fab-a5bd-ba3851ae8b56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CV-Parsing-using-Spacy-3'...\n",
            "remote: Enumerating objects: 82, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 82 (delta 14), reused 74 (delta 14), pack-reused 6 (from 1)\u001b[K\n",
            "Receiving objects: 100% (82/82), 5.62 MiB | 30.43 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/laxmimerit/CV-Parsing-using-Spacy-3.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U00nOGF6n2vk"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "cv_data = json.load(open('/content/CV-Parsing-using-Spacy-3/data/training/train_data.json','r'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6QlMtdopRVH"
      },
      "outputs": [],
      "source": [
        "#cv_data[:5] # View the first 5 items of the list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kD0N0DvINrIi",
        "outputId": "20d71d36-0537-4200-fe86-341cead35d77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(cv_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftB0dw1rattX"
      },
      "outputs": [],
      "source": [
        "# you can see the data(json) by uncommenting below statement\n",
        "#cv_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E96G8LV4SV8",
        "outputId": "9b30cace-8108-4b93-c4c9-c5db9859edb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Created output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[38;5;1m✘ Config validation error\u001b[0m\n",
            "training -> optimizer\tfound conflicting values\n",
            "{'paths': {'train': './train_data.spacy', 'dev': './dev_data.spacy', 'vectors': None}, 'system': {'gpu_allocator': 'pytorch'}, 'nlp': {'lang': 'en', 'pipeline': ['transformer', 'ner'], 'batch_size': 8}, 'components': {'ner': {'factory': 'ner'}, 'transformer': {'factory': 'transformer'}}, 'training': {'optimizer': 'Adam', 'dropout': 0.2, 'patience': 5, 'max_epochs': 20, 'batch_size': 8}}\n",
            "{'training': {'@optimizers': '\"Adam\"', 'learn_rate': '0.00005'}}\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy train config.cfg --output ./output --gpu-id 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biYUMq1spsd1",
        "outputId": "cd9a13e5-9ccf-470a-cd49-d9a4a3bfcf49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "/content/CV-Parsing-using-Spacy-3/data/training/config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy init fill-config /content/CV-Parsing-using-Spacy-3/data/training/base_config.cfg /content/CV-Parsing-using-Spacy-3/data/training/config.cfg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCv9ydcoYhV_"
      },
      "source": [
        "---\n",
        "config.cfg must be modified in order to reduce the training time<br>\n",
        "(generated in *content/CV-Parsing-using-Spacy-3/data/training/config.cfg*)<br><br>\n",
        "max_steps parameter must be set to some low number like 2000 or 4000, which will drastically reduce the training time.</h3>\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OJ7_SGfamRK"
      },
      "source": [
        "This function takes a dataset of text and annotations, processes each text to identify and label entities, and stores the results in a DocBin object that can be used for further training or analysis with spaCy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z54oCPNspsaZ"
      },
      "outputs": [],
      "source": [
        "def get_spacy_doc(file, data):\n",
        "  nlp = spacy.blank('en')\n",
        "  db = DocBin()\n",
        "  for text, annot in tqdm(data):\n",
        "    doc = nlp.make_doc(text)\n",
        "    annot = annot['entities']\n",
        "\n",
        "    ents = []\n",
        "    entity_indices = []\n",
        "\n",
        "    for start, end, label in annot:\n",
        "      skip_entity = False\n",
        "      for idx in range(start, end):\n",
        "        if idx in entity_indices:\n",
        "          skip_entity = True\n",
        "          break\n",
        "      if skip_entity == True:\n",
        "        continue\n",
        "      entity_indices = entity_indices + list(range(start, end))\n",
        "      try:\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode='strict')\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "      if span is None:\n",
        "        err_data = str([start, end]) + ' ' + str(text) + '\\n'\n",
        "        file.write(err_data)\n",
        "      else :\n",
        "        ents.append(span)\n",
        "    try:\n",
        "      doc.ents = ents\n",
        "      db.add(doc)\n",
        "    except:\n",
        "      pass\n",
        "      #print(text)\n",
        "  return db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFpv06L-kcC0",
        "outputId": "3980e588-bbb0-4993-a31a-b38bf002ed63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.2.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-02 14:13:18,225] A new study created in memory with name: no-name-301d94d1-d905-4118-8303-fd08ab55251f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/__main__.py\", line 4, in <module>\n",
            "    setup_cli()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/cli/_util.py\", line 87, in setup_cli\n",
            "    command(prog_name=COMMAND)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1161, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/typer/core.py\", line 740, in main\n",
            "    return _main(\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/typer/core.py\", line 195, in _main\n",
            "    rv = self.invoke(ctx)\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1697, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1443, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 788, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/typer/main.py\", line 697, in wrapper\n",
            "    return callback(**use_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/cli/train.py\", line 54, in train_cli\n",
            "    train(config_path, output_path, use_gpu=use_gpu, overrides=overrides)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/cli/train.py\", line 81, in train\n",
            "    nlp = init_nlp(config, use_gpu=use_gpu)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/training/initialize.py\", line 68, in init_nlp\n",
            "    train_corpus, dev_corpus = resolve_dot_names(config, dot_names)\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/util.py\", line 639, in resolve_dot_names\n",
            "    result = registry.resolve(config[section])\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/confection/__init__.py\", line 760, in resolve\n",
            "    resolved, _ = cls._make(\n",
            "                  ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/confection/__init__.py\", line 809, in _make\n",
            "    filled, _, resolved = cls._fill(\n",
            "                          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/confection/__init__.py\", line 881, in _fill\n",
            "    getter_result = getter(*args, **kwargs)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/training/corpus.py\", line 31, in create_docbin_reader\n",
            "    raise ValueError(Errors.E913)\n",
            "ValueError: [E913] Corpus path can't be None. Maybe you forgot to define it in your .cfg file or override it on the CLI?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-02 14:13:25,555] Trial 0 finished with value: 0.0 and parameters: {'dropout': 0.2518909335431776, 'batch_size': 64}. Best is trial 0 with value: 0.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model not found at ./output/model-best. Check training output.\n",
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/__main__.py\", line 4, in <module>\n",
            "    setup_cli()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/cli/_util.py\", line 87, in setup_cli\n",
            "    command(prog_name=COMMAND)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1161, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/typer/core.py\", line 740, in main\n",
            "    return _main(\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/typer/core.py\", line 195, in _main\n",
            "    rv = self.invoke(ctx)\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1697, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1443, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 788, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/typer/main.py\", line 697, in wrapper\n",
            "    return callback(**use_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/cli/train.py\", line 54, in train_cli\n",
            "    train(config_path, output_path, use_gpu=use_gpu, overrides=overrides)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/cli/train.py\", line 81, in train\n",
            "    nlp = init_nlp(config, use_gpu=use_gpu)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/training/initialize.py\", line 68, in init_nlp\n",
            "    train_corpus, dev_corpus = resolve_dot_names(config, dot_names)\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/util.py\", line 639, in resolve_dot_names\n",
            "    result = registry.resolve(config[section])\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/confection/__init__.py\", line 760, in resolve\n",
            "    resolved, _ = cls._make(\n",
            "                  ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/confection/__init__.py\", line 809, in _make\n",
            "    filled, _, resolved = cls._fill(\n",
            "                          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/confection/__init__.py\", line 881, in _fill\n",
            "    getter_result = getter(*args, **kwargs)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/training/corpus.py\", line 31, in create_docbin_reader\n",
            "    raise ValueError(Errors.E913)\n",
            "ValueError: [E913] Corpus path can't be None. Maybe you forgot to define it in your .cfg file or override it on the CLI?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-02 14:13:33,384] Trial 1 finished with value: 0.0 and parameters: {'dropout': 0.1424532825922215, 'batch_size': 64}. Best is trial 0 with value: 0.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model not found at ./output/model-best. Check training output.\n",
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/__main__.py\", line 4, in <module>\n",
            "    setup_cli()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/cli/_util.py\", line 87, in setup_cli\n",
            "    command(prog_name=COMMAND)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1161, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/typer/core.py\", line 740, in main\n",
            "    return _main(\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/typer/core.py\", line 195, in _main\n",
            "    rv = self.invoke(ctx)\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1697, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1443, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 788, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/typer/main.py\", line 697, in wrapper\n",
            "    return callback(**use_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/cli/train.py\", line 54, in train_cli\n",
            "    train(config_path, output_path, use_gpu=use_gpu, overrides=overrides)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/cli/train.py\", line 81, in train\n",
            "    nlp = init_nlp(config, use_gpu=use_gpu)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/training/initialize.py\", line 68, in init_nlp\n",
            "    train_corpus, dev_corpus = resolve_dot_names(config, dot_names)\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/util.py\", line 639, in resolve_dot_names\n",
            "    result = registry.resolve(config[section])\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/confection/__init__.py\", line 760, in resolve\n",
            "    resolved, _ = cls._make(\n",
            "                  ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/confection/__init__.py\", line 809, in _make\n",
            "    filled, _, resolved = cls._fill(\n",
            "                          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/confection/__init__.py\", line 881, in _fill\n",
            "    getter_result = getter(*args, **kwargs)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/training/corpus.py\", line 31, in create_docbin_reader\n",
            "    raise ValueError(Errors.E913)\n",
            "ValueError: [E913] Corpus path can't be None. Maybe you forgot to define it in your .cfg file or override it on the CLI?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-02 14:13:41,113] Trial 2 finished with value: 0.0 and parameters: {'dropout': 0.12026071474455038, 'batch_size': 32}. Best is trial 0 with value: 0.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model not found at ./output/model-best. Check training output.\n",
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/__main__.py\", line 4, in <module>\n",
            "    setup_cli()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/cli/_util.py\", line 87, in setup_cli\n",
            "    command(prog_name=COMMAND)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1161, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/typer/core.py\", line 740, in main\n",
            "    return _main(\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/typer/core.py\", line 195, in _main\n",
            "    rv = self.invoke(ctx)\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1697, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1443, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 788, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/typer/main.py\", line 697, in wrapper\n",
            "    return callback(**use_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/cli/train.py\", line 54, in train_cli\n",
            "    train(config_path, output_path, use_gpu=use_gpu, overrides=overrides)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/cli/train.py\", line 81, in train\n",
            "    nlp = init_nlp(config, use_gpu=use_gpu)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/training/initialize.py\", line 68, in init_nlp\n",
            "    train_corpus, dev_corpus = resolve_dot_names(config, dot_names)\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/util.py\", line 639, in resolve_dot_names\n",
            "    result = registry.resolve(config[section])\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/confection/__init__.py\", line 760, in resolve\n",
            "    resolved, _ = cls._make(\n",
            "                  ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/confection/__init__.py\", line 809, in _make\n",
            "    filled, _, resolved = cls._fill(\n",
            "                          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/confection/__init__.py\", line 881, in _fill\n",
            "    getter_result = getter(*args, **kwargs)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/training/corpus.py\", line 31, in create_docbin_reader\n",
            "    raise ValueError(Errors.E913)\n",
            "ValueError: [E913] Corpus path can't be None. Maybe you forgot to define it in your .cfg file or override it on the CLI?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-02 14:13:48,151] Trial 3 finished with value: 0.0 and parameters: {'dropout': 0.11561644092511143, 'batch_size': 32}. Best is trial 0 with value: 0.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model not found at ./output/model-best. Check training output.\n",
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/__main__.py\", line 4, in <module>\n",
            "    setup_cli()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/cli/_util.py\", line 87, in setup_cli\n",
            "    command(prog_name=COMMAND)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1161, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/typer/core.py\", line 740, in main\n",
            "    return _main(\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/typer/core.py\", line 195, in _main\n",
            "    rv = self.invoke(ctx)\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1697, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1443, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 788, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/typer/main.py\", line 697, in wrapper\n",
            "    return callback(**use_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/cli/train.py\", line 54, in train_cli\n",
            "    train(config_path, output_path, use_gpu=use_gpu, overrides=overrides)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/cli/train.py\", line 81, in train\n",
            "    nlp = init_nlp(config, use_gpu=use_gpu)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/training/initialize.py\", line 68, in init_nlp\n",
            "    train_corpus, dev_corpus = resolve_dot_names(config, dot_names)\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/util.py\", line 639, in resolve_dot_names\n",
            "    result = registry.resolve(config[section])\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/confection/__init__.py\", line 760, in resolve\n",
            "    resolved, _ = cls._make(\n",
            "                  ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/confection/__init__.py\", line 809, in _make\n",
            "    filled, _, resolved = cls._fill(\n",
            "                          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/confection/__init__.py\", line 881, in _fill\n",
            "    getter_result = getter(*args, **kwargs)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/training/corpus.py\", line 31, in create_docbin_reader\n",
            "    raise ValueError(Errors.E913)\n",
            "ValueError: [E913] Corpus path can't be None. Maybe you forgot to define it in your .cfg file or override it on the CLI?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-02 14:13:56,179] Trial 4 finished with value: 0.0 and parameters: {'dropout': 0.1687621046479339, 'batch_size': 32}. Best is trial 0 with value: 0.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model not found at ./output/model-best. Check training output.\n",
            "Best Hyperparameters: {'dropout': 0.2518909335431776, 'batch_size': 64}\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna\n",
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.3)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
        "\n",
        "    # Update config.cfg\n",
        "    with open(\"/content/CV-Parsing-using-Spacy-3/data/training/config.cfg\", \"r\") as file:\n",
        "        config = file.read()\n",
        "\n",
        "    config = config.replace(\"dropout = 0.2\", f\"dropout = {dropout}\")\n",
        "    config = config.replace(\"batch_size = 32\", f\"batch_size = {batch_size}\")\n",
        "\n",
        "    with open(\"/content/CV-Parsing-using-Spacy-3/data/training/config.cfg\", \"w\") as file:\n",
        "        file.write(config)\n",
        "\n",
        "    # Train the model\n",
        "    !python -m spacy train /content/CV-Parsing-using-Spacy-3/data/training/config.cfg --output ./output --gpu-id 0\n",
        "\n",
        "    # Check if the model was created\n",
        "    import os\n",
        "    if os.path.exists(\"./output/model-best\"):  # Check if the model directory exists\n",
        "        # Load trained model and evaluate\n",
        "        nlp = spacy.load(\"./output/model-best\")\n",
        "        test_text = \"John Doe worked at Microsoft as a Data Scientist from 2019-2023.\"\n",
        "        doc = nlp(test_text)\n",
        "\n",
        "        return len(doc.ents)  # Optimize based on entity count\n",
        "    else:\n",
        "        print(\"Model not found at ./output/model-best. Check training output.\")\n",
        "        return 0  # Return a default value if the model is not found\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=5)\n",
        "\n",
        "print(\"Best Hyperparameters:\", study.best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Yp9vtIvkche"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsxMgzn0psYy"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(cv_data, test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frBj3E2HpsWE",
        "outputId": "aa276a4f-96b9-4af9-96fe-3f66b0045c70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 140/140 [00:01<00:00, 100.60it/s]\n",
            "100%|██████████| 60/60 [00:00<00:00, 65.38it/s]\n"
          ]
        }
      ],
      "source": [
        "file = open('error.txt', 'w')\n",
        "db = get_spacy_doc(file, train)\n",
        "db.to_disk('train_data.spacy')\n",
        "\n",
        "db = get_spacy_doc(file, test)\n",
        "db.to_disk('test_data.spacy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXSbjy3IpsTW",
        "outputId": "bf5ec7bd-103e-4f79-b383-adb7f86f7397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 112kB/s]\n",
            "config.json: 100% 481/481 [00:00<00:00, 4.20MB/s]\n",
            "vocab.json: 100% 899k/899k [00:00<00:00, 19.8MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 40.6MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 16.7MB/s]\n",
            "2025-04-02 14:15:40.738562: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743603340.975714    5889 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743603341.041020    5889 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-02 14:15:41.547103: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "model.safetensors: 100% 499M/499M [00:02<00:00, 198MB/s]\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0        1554.16   1622.80    0.42    0.21    8.14    0.00\n",
            "  4     200      379963.18  72593.16    0.00    0.00    0.00    0.00\n",
            "  8     400       79182.64  25770.21   51.18   52.54   49.89    0.51\n",
            " 12     600       12242.72  20978.31   52.94   54.86   51.15    0.53\n",
            " 16     800        2827.62  17652.20   51.23   48.00   54.93    0.51\n",
            " 20    1000        1743.37  16056.21   52.47   51.97   52.98    0.52\n",
            " 24    1200        1835.04  15394.33   51.68   60.78   44.95    0.52\n",
            " 28    1400         869.27  14440.95   55.75   54.56   57.00    0.56\n",
            " 32    1600       12445.83  14020.57   55.13   57.06   53.33    0.55\n",
            " 36    1800         762.82  13353.10   53.49   50.30   57.11    0.53\n",
            " 40    2000       10358.86  12970.02   54.47   52.15   57.00    0.54\n",
            " 44    2200        7862.16  12440.48   54.90   54.52   55.28    0.55\n",
            " 48    2400        1992.38  11764.08   53.92   53.50   54.36    0.54\n",
            " 52    2600         747.59  11073.52   57.77   58.21   57.34    0.58\n",
            " 56    2800         294.73  10384.41   57.88   57.85   57.91    0.58\n",
            " 60    3000       37751.85   9784.42   57.51   58.89   56.19    0.58\n",
            " 64    3200       22620.93   8746.15   57.58   59.56   55.73    0.58\n",
            " 68    3400         139.28   7554.16   57.77   61.94   54.13    0.58\n",
            " 72    3600        2800.66   6558.98   56.49   63.78   50.69    0.56\n",
            " 76    3800        1066.58   5359.58   56.09   61.91   51.26    0.56\n",
            " 80    4000       44486.53   4410.78   55.33   64.38   48.51    0.55\n",
            " 84    4200         164.07   3138.79   56.31   64.26   50.11    0.56\n",
            " 88    4400        4540.60   2333.29   54.30   61.12   48.85    0.54\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output/model-last\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy train /content/CV-Parsing-using-Spacy-3/data/training/config.cfg --output ./output --paths.train ./train_data.spacy --paths.dev ./test_data.spacy --gpu-id 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA2OcJgxHBr8"
      },
      "source": [
        "<h3>Testing the Trained Model</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzwZDEUjpsPc"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('/content/output/model-best')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NXhYafFtpsJ9",
        "outputId": "4bf19200-1803-48b5-f525-552f35176f3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XksnzmCd5z6y",
        "outputId": "6546f708-2d3e-40e4-cc86-cca42ffcc63a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Downloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pdfminer.six\n",
            "Successfully installed pdfminer.six-20250327\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfminer.six"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ot_MuMut1o4t"
      },
      "outputs": [],
      "source": [
        "# from pdfminer.high_level import extract_text\n",
        "\n",
        "# text = extract_text(\"/content/M_Abdullah_Resume.pdf\")\n",
        "# print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Xkw_Vay2I5F"
      },
      "outputs": [],
      "source": [
        "# doc = nlp(text)\n",
        "# for ent in doc.ents:\n",
        "#   print(ent.text, '---->' , ent.label_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing\n"
      ],
      "metadata": {
        "id": "iCGy_UCE3GcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load your trained model\n",
        "nlp = spacy.load(\"output/model-last\")"
      ],
      "metadata": {
        "id": "WdHAPYuC3AmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Read resume text\n",
        "# from pdfminer.high_level import extract_text\n",
        "# text = extract_text(\"/content/M_Abdullah_Resume.pdf\")"
      ],
      "metadata": {
        "id": "usY283qg3CLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Process with NER model\n",
        "# doc = nlp(text)\n",
        "# for ent in doc.ents:\n",
        "#     print(ent.text, \"---->\", ent.label_)"
      ],
      "metadata": {
        "id": "91ndwJzt3DjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import spacy\n",
        "# from spacy.matcher import Matcher\n",
        "# import re\n",
        "# from pdfminer.high_level import extract_text\n",
        "\n",
        "# # Load the trained model\n",
        "# nlp = spacy.load(\"output/model-last\")\n",
        "\n",
        "# # Extract text from the new resume\n",
        "# text = extract_text(\"/content/Muhammad Fareed Full Stack Developer Resume - Muhammad Fareed.pdf\")\n",
        "# doc = nlp(text)\n",
        "\n",
        "# # Store extracted entities in a dictionary to remove duplicates\n",
        "# extracted_data = {\"Name\": set(), \"Degree\": set(), \"College Name\": set(), \"Location\": set(), \"Skills\": set()}\n",
        "\n",
        "# # Extract NER results\n",
        "# for ent in doc.ents:\n",
        "#     extracted_data[ent.label_].add(ent.text)\n",
        "\n",
        "# # Extract experience using regex\n",
        "# exp_pattern = re.findall(r'(\\d+)\\+?\\s*years?\\s*of\\s*experience', text, re.IGNORECASE)\n",
        "# if exp_pattern:\n",
        "#     extracted_data[\"Experience\"] = {exp_pattern[0] + \" years\"}\n",
        "\n",
        "# # Rule-based matching for skills\n",
        "# matcher = Matcher(nlp.vocab)\n",
        "# skills_patterns = [\n",
        "#     [{\"LOWER\": \"python\"}],\n",
        "#     [{\"LOWER\": \"javascript\"}],\n",
        "#     [{\"LOWER\": \"machine\"}, {\"LOWER\": \"learning\"}],\n",
        "#     [{\"LOWER\": \"data\"}, {\"LOWER\": \"science\"}],\n",
        "#     [{\"LOWER\": \"mern\"}, {\"LOWER\": \"stack\"}],\n",
        "#     [{\"LOWER\": \"react\"}],\n",
        "#     [{\"LOWER\": \"firebase\"}],\n",
        "#     [{\"LOWER\": \"fast\"}, {\"LOWER\": \"api\"}],\n",
        "#     [{\"LOWER\": \"solidity\"}],\n",
        "#     [{\"LOWER\": \"postgresql\"}]\n",
        "# ]\n",
        "# matcher.add(\"SKILLS\", skills_patterns)\n",
        "\n",
        "# matches = matcher(doc)\n",
        "# for match_id, start, end in matches:\n",
        "#     extracted_data[\"Skills\"].add(doc[start:end].text)\n",
        "\n",
        "# # Display the cleaned-up results\n",
        "# print(\"---- Cleaned Entity Recognition Output ----\")\n",
        "# for key, values in extracted_data.items():\n",
        "#     if values:\n",
        "#         print(f\"{key}: {', '.join(values)}\")\n"
      ],
      "metadata": {
        "id": "AnadhzWA3efl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import spacy\n",
        "# from spacy.matcher import Matcher\n",
        "# import re\n",
        "# from pdfminer.high_level import extract_text\n",
        "\n",
        "# # Load the trained model\n",
        "# nlp = spacy.load(\"output/model-last\")\n",
        "\n",
        "# # Extract text from the new resume\n",
        "# text = extract_text(\"/content/Muhammad Fareed Full Stack Developer Resume - Muhammad Fareed.pdf\")\n",
        "# doc = nlp(text)\n",
        "\n",
        "# # Store extracted entities in a dictionary to remove duplicates\n",
        "# extracted_data = {\"Name\": set(), \"Degree\": set(), \"College Name\": set(), \"Location\": set(), \"Skills\": set()}\n",
        "\n",
        "# # Extract NER results\n",
        "# for ent in doc.ents:\n",
        "#     extracted_data[ent.label_].add(ent.text)\n",
        "\n",
        "# # Extract experience using regex\n",
        "# exp_pattern = re.findall(r'(\\d+)\\+?\\s*years?\\s*of\\s*experience', text, re.IGNORECASE)\n",
        "# if exp_pattern:\n",
        "#     extracted_data[\"Experience\"] = {exp_pattern[0] + \" years\"}\n",
        "\n",
        "# # Rule-based matching for skills\n",
        "# matcher = Matcher(nlp.vocab)\n",
        "# skills_patterns = [\n",
        "#     [{\"LOWER\": \"python\"}],\n",
        "#     [{\"LOWER\": \"javascript\"}],\n",
        "#     [{\"LOWER\": \"machine\"}, {\"LOWER\": \"learning\"}],\n",
        "#     [{\"LOWER\": \"data\"}, {\"LOWER\": \"science\"}],\n",
        "#     [{\"LOWER\": \"mern\"}, {\"LOWER\": \"stack\"}],\n",
        "#     [{\"LOWER\": \"react\"}],\n",
        "#     [{\"LOWER\": \"firebase\"}],\n",
        "#     [{\"LOWER\": \"fast\"}, {\"LOWER\": \"api\"}],\n",
        "#     [{\"LOWER\": \"solidity\"}],\n",
        "#     [{\"LOWER\": \"postgresql\"}]\n",
        "# ]\n",
        "# matcher.add(\"SKILLS\", skills_patterns)\n",
        "\n",
        "# matches = matcher(doc)\n",
        "# for match_id, start, end in matches:\n",
        "#     extracted_data[\"Skills\"].add(doc[start:end].text)\n",
        "\n",
        "# # Display the cleaned-up results\n",
        "# print(\"---- Cleaned Entity Recognition Output ----\")\n",
        "# for key, values in extracted_data.items():\n",
        "#     if values:\n",
        "#         print(f\"{key}: {', '.join(values)}\")\n"
      ],
      "metadata": {
        "id": "SLpaj0LTGsyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import spacy\n",
        "# import re\n",
        "# from pdfminer.high_level import extract_text\n",
        "# from dateutil import parser\n",
        "# from datetime import datetime\n",
        "\n",
        "# # Load the trained NER model\n",
        "# nlp = spacy.load(\"output/model-last\")\n",
        "\n",
        "# # Extract text from the resume\n",
        "# text = extract_text(\"/content/Muhammad Fareed Full Stack Developer Resume - Muhammad Fareed.pdf\")\n",
        "# doc = nlp(text)\n",
        "\n",
        "# # Store extracted entities in a dictionary\n",
        "# extracted_data = {\n",
        "#     \"Name\": set(),\n",
        "#     \"Degree\": set(),\n",
        "#     \"College Name\": set(),\n",
        "#     \"Location\": set(),\n",
        "#     \"Skills\": set(),\n",
        "#     \"Experience\": set(),\n",
        "# }\n",
        "\n",
        "# # Extract Named Entities (NER)\n",
        "# for ent in doc.ents:\n",
        "#     extracted_data[ent.label_].add(ent.text)\n",
        "\n",
        "# # Extract job experience details (using regex)\n",
        "# experience_pattern = re.findall(\n",
        "#     r\"([\\w\\s\\-/]+)\\s*[\\n]*\\s*(\\w+\\s*\\d{4})\\s*–\\s*(\\w+\\s*\\d{4}|Present)\", text\n",
        "# )\n",
        "\n",
        "# total_experience = 0\n",
        "# for job_title, start_date, end_date in experience_pattern:\n",
        "#     try:\n",
        "#         start_date = parser.parse(start_date)\n",
        "#         end_date = (\n",
        "#             parser.parse(end_date) if \"Present\" not in end_date else datetime.today()\n",
        "#         )\n",
        "#         experience_months = (end_date.year - start_date.year) * 12 + (\n",
        "#             end_date.month - start_date.month\n",
        "#         )\n",
        "#         total_experience += experience_months\n",
        "#         extracted_data[\"Experience\"].add(\n",
        "#             f\"{job_title.strip()} ({start_date.strftime('%b %Y')} - {end_date.strftime('%b %Y')})\"\n",
        "#         )\n",
        "#     except Exception:\n",
        "#         continue  # Skip parsing errors\n",
        "\n",
        "# # Rule-based matching for skills\n",
        "# matcher = Matcher(nlp.vocab)\n",
        "# skills_patterns = [\n",
        "#     [{\"LOWER\": \"python\"}],\n",
        "#     [{\"LOWER\": \"javascript\"}],\n",
        "#     [{\"LOWER\": \"machine\"}, {\"LOWER\": \"learning\"}],\n",
        "#     [{\"LOWER\": \"data\"}, {\"LOWER\": \"science\"}],\n",
        "#     [{\"LOWER\": \"mern\"}, {\"LOWER\": \"stack\"}],\n",
        "#     [{\"LOWER\": \"react\"}],\n",
        "#     [{\"LOWER\": \"firebase\"}],\n",
        "#     [{\"LOWER\": \"fast\"}, {\"LOWER\": \"api\"}],\n",
        "#     [{\"LOWER\": \"solidity\"}],\n",
        "#     [{\"LOWER\": \"postgresql\"}]\n",
        "# ]\n",
        "# matcher.add(\"SKILLS\", skills_patterns)\n",
        "\n",
        "# matches = matcher(doc)\n",
        "# for match_id, start, end in matches:\n",
        "#     extracted_data[\"Skills\"].add(doc[start:end].text)\n",
        "\n",
        "\n",
        "# # Convert total experience to years & months\n",
        "# if total_experience > 0:\n",
        "#     years, months = divmod(total_experience, 12)\n",
        "#     extracted_data[\"Total Experience\"] = f\"{years} years {months} months\"\n",
        "\n",
        "# # Display the cleaned-up results\n",
        "# print(\"\\n---- Extracted Information ----\")\n",
        "# for key, values in extracted_data.items():\n",
        "#     if values:\n",
        "#         print(f\"{key}: {','.join(values)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "cxzDEo5UHsmZ",
        "outputId": "aef6ccc8-a888-49a0-a638-34324b7bc47a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Designation'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-565fea998967>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Extract Named Entities (NER)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mextracted_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Extract job experience details (using regex)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Designation'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import re\n",
        "from pdfminer.high_level import extract_text\n",
        "from dateutil import parser\n",
        "from datetime import datetime\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# Load the trained NER model\n",
        "nlp = spacy.load(\"output/model-last\")\n",
        "\n",
        "# Extract text from the resume\n",
        "text = extract_text(\"/content/Muhammad Fareed Full Stack Developer Resume - Muhammad Fareed.pdf\")\n",
        "doc = nlp(text)\n",
        "\n",
        "# Store extracted entities dynamically\n",
        "extracted_data = {\n",
        "    \"Name\": set(),\n",
        "    # \"Degree\": set(),\n",
        "    \"College Name\": set(),\n",
        "    \"Location\": set(),\n",
        "    \"Skills\": set(),\n",
        "    \"Experience\": set(),\n",
        "}\n",
        "\n",
        "# Extract Named Entities (NER)\n",
        "for ent in doc.ents:\n",
        "    entity_label = ent.label_\n",
        "\n",
        "    # If a new entity appears (e.g., 'Designation'), add it dynamically\n",
        "    if entity_label not in extracted_data:\n",
        "        extracted_data[entity_label] = set()\n",
        "\n",
        "    extracted_data[entity_label].add(ent.text.strip())\n",
        "\n",
        "# Extract job experience details using regex\n",
        "experience_pattern = re.findall(\n",
        "    r\"([\\w\\s\\-/]+)\\s*[\\n]*\\s*(\\w+\\s*\\d{4})\\s*–\\s*(\\w+\\s*\\d{4}|Present)\", text\n",
        ")\n",
        "\n",
        "total_experience = 0\n",
        "for job_title, start_date, end_date in experience_pattern:\n",
        "    try:\n",
        "        start_date = parser.parse(start_date)\n",
        "        end_date = parser.parse(end_date) if \"Present\" not in end_date else datetime.today()\n",
        "\n",
        "        experience_months = (end_date.year - start_date.year) * 12 + (end_date.month - start_date.month)\n",
        "        total_experience += experience_months\n",
        "\n",
        "        extracted_data[\"Experience\"].add(\n",
        "            f\"{job_title.strip()} ({start_date.strftime('%b %Y')} - {end_date.strftime('%b %Y')})\"\n",
        "        )\n",
        "    except Exception:\n",
        "        continue  # Skip parsing errors\n",
        "\n",
        "# Convert total experience to years & months\n",
        "if total_experience > 0:\n",
        "    years, months = divmod(total_experience, 12)\n",
        "    extracted_data[\"Total Experience\"] = {f\"{years} years {months} months\"}\n",
        "\n",
        "# Rule-based matching for skills\n",
        "matcher = Matcher(nlp.vocab)\n",
        "skills_patterns = [\n",
        "    [{\"LOWER\": \"python\"}],\n",
        "    [{\"LOWER\": \"javascript\"}],\n",
        "    [{\"LOWER\": \"machine\"}, {\"LOWER\": \"learning\"}],\n",
        "    [{\"LOWER\": \"data\"}, {\"LOWER\": \"science\"}],\n",
        "    [{\"LOWER\": \"mern\"}, {\"LOWER\": \"stack\"}],\n",
        "    [{\"LOWER\": \"react\"}],\n",
        "    [{\"LOWER\": \"firebase\"}],\n",
        "    [{\"LOWER\": \"fast\"}, {\"LOWER\": \"api\"}],\n",
        "    [{\"LOWER\": \"solidity\"}],\n",
        "    [{\"LOWER\": \"postgresql\"}]\n",
        "]\n",
        "matcher.add(\"SKILLS\", skills_patterns)\n",
        "\n",
        "matches = matcher(doc)\n",
        "for match_id, start, end in matches:\n",
        "    extracted_data[\"Skills\"].add(doc[start:end].text)\n",
        "\n",
        "# Convert sets to lists and print results\n",
        "print(\"\\n---- Extracted Information ----\")\n",
        "for key, values in extracted_data.items():\n",
        "    if values:\n",
        "        print(f\"{key}: {', '.join(values)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMRfXmc6IX_M",
        "outputId": "486a8749-c486-4443-d957-b5379926d1f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---- Extracted Information ----\n",
            "Name: MUHAMMAD FAREED, Muhammad Fareed\n",
            "Degree: Bachelor in Computer Science (7 semester)\n",
            "Saylani Mass & IT Training Program (SMIT)\n",
            "Web and App Development\n",
            "College Name: Hamdard University\n",
            "Skills: PostgreSQL, Firebase, MERN stack, Solidity, MERN Stack, FAST API, React, Python, JavaScript\n",
            "Experience: WORK EXPERIENCE\n",
            "\n",
            "Frontend Developer / Elearning Avenue\n",
            "\n",
            "Oc (Apr 2022 - May 2023)\n",
            "Designation: M E R N\n",
            "Total Experience: 1 years 1 months\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import spacy\n",
        "# import re\n",
        "# from pdfminer.high_level import extract_text\n",
        "# from dateutil import parser\n",
        "# from datetime import datetime\n",
        "\n",
        "# # Load the trained NER model\n",
        "# nlp = spacy.load(\"output/model-last\")\n",
        "\n",
        "# # Extract text from the resume\n",
        "# text = extract_text(\"/content/Muhammad Fareed Full Stack Developer Resume - Muhammad Fareed.pdf\")\n",
        "# doc = nlp(text)\n",
        "\n",
        "# # Store extracted entities in a dictionary (Use Sets to Avoid Duplicates)\n",
        "# extracted_data = {\n",
        "#     \"Name\": set(),\n",
        "#     \"Degree\": set(),\n",
        "#     \"College Name\": set(),\n",
        "#     \"Location\": set(),\n",
        "#     \"Skills\": set(),\n",
        "#     \"Experience\": set(),\n",
        "# }\n",
        "\n",
        "# # Extract Named Entities (NER)\n",
        "# for ent in doc.ents:\n",
        "#     extracted_data[ent.label_].add(ent.text.strip())\n",
        "\n",
        "# # Remove unwanted terms from Skills & Degree\n",
        "# invalid_terms = {\"SKILLS\", \"SUMMARY\", \"WORK EXPERIENCE\", \"EDUCATION\"}\n",
        "# extracted_data[\"Degree\"] -= invalid_terms\n",
        "# extracted_data[\"Skills\"] -= invalid_terms\n",
        "\n",
        "# # Extract skills manually (if missing from NER)\n",
        "# skills_section = re.findall(\n",
        "#     r\"(?i)(?:Skills|Technical Skills|Expertise|SKILLS SUMMARY)[\\s\\S]*?(?=\\n\\n|\\Z)\", text\n",
        "# )\n",
        "# if skills_section:\n",
        "#     skills = re.findall(r\"\\b[A-Za-z#.\\-+]+\\b\", skills_section[0])\n",
        "#     extracted_data[\"Skills\"].update(skill for skill in skills if skill.upper() not in invalid_terms)\n",
        "\n",
        "# # Extract job experience details (using regex)\n",
        "# experience_pattern = re.findall(\n",
        "#     r\"([\\w\\s\\-/]+)\\s*[\\n]*\\s*(\\w+\\s*\\d{4})\\s*–\\s*(\\w+\\s*\\d{4}|Present)\", text\n",
        "# )\n",
        "\n",
        "# total_experience_months = 0\n",
        "# for job_title, start_date, end_date in experience_pattern:\n",
        "#     try:\n",
        "#         start_date = parser.parse(start_date)\n",
        "#         end_date = (\n",
        "#             parser.parse(end_date) if \"Present\" not in end_date else datetime.today()\n",
        "#         )\n",
        "#         experience_months = (end_date.year - start_date.year) * 12 + (\n",
        "#             end_date.month - start_date.month\n",
        "#         )\n",
        "#         total_experience_months += experience_months\n",
        "\n",
        "#         extracted_data[\"Experience\"].add(\n",
        "#             f\"{job_title.strip()} ({start_date.strftime('%b %Y')} - {end_date.strftime('%b %Y')})\"\n",
        "#         )\n",
        "#     except Exception:\n",
        "#         continue  # Skip parsing errors\n",
        "\n",
        "# # Convert total experience to years & months\n",
        "# if total_experience_months > 0:\n",
        "#     years, months = divmod(total_experience_months, 12)\n",
        "#     extracted_data[\"Total Experience\"] = f\"{years} years {months} months\"\n",
        "\n",
        "# # Remove duplicates & format results properly\n",
        "# for key in extracted_data:\n",
        "#     extracted_data[key] = list(set(extracted_data[key]))  # Convert sets to lists\n",
        "\n",
        "# # Display the cleaned-up results\n",
        "# print(\"\\n---- Extracted Information ----\")\n",
        "# for key, values in extracted_data.items():\n",
        "#     if values:\n",
        "#          print(f\"{key}: {' '.join(values)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuzySYdtLGao",
        "outputId": "2ef52120-1ee0-4175-f735-401bdbb687b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---- Extracted Information ----\n",
            "Name: MUHAMMAD FAREED Muhammad Fareed\n",
            "Degree: Bachelor in Computer Science\n",
            "College Name: Hamdard University Saylani Mass & IT Training Program (SMIT)\n",
            "Web and App Development\n",
            "Location: Karachi S T M E\n",
            "Experience: WORK EXPERIENCE\n",
            "\n",
            "Frontend Developer / Elearning Avenue\n",
            "\n",
            "Oc (Apr 2022 - May 2023)\n",
            "Total Experience: h   t y 1 o m n r s e a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---- Full Resume Text ----\")\n",
        "print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xZi0d1e39ms",
        "outputId": "05572109-7324-4218-adaf-5035c0029d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- Full Resume Text ----\n",
            "MUHAMMAD FAREED\n",
            "M E R N   S T A C K   D E V E L O P E R\n",
            "\n",
            "Muhammad Fareed / LinkedIn\n",
            "mfareed1947 / github\n",
            "\n",
            "Hamdard University\n",
            "Bachelor in Computer Science (7 semester)\n",
            "Saylani Mass & IT Training Program (SMIT)\n",
            "Web and App Development\n",
            "\n",
            "EDUCATION\n",
            "\n",
            "Email: mfareed1504@gmail.com\n",
            "Mobile: +92 3043686779\n",
            "\n",
            "Karachi, Pakistan\n",
            "Nov 2021 – Present\n",
            "Karachi, Pakistan\n",
            "Jan 2021 – 2022\n",
            "\n",
            "• Languages:\n",
            "\n",
            "JavaScript, Python, Typescript , Solidity , Node Js , PostgreSQL\n",
            "\n",
            "• Frameworks:\n",
            "\n",
            "React Js, Next Js, Nuxt Js, Express Js, FAST API, Gatsby Js\n",
            "\n",
            "• Tools:\n",
            "\n",
            "Tailwind CSS, MUI, Shadcn UI, Style component\n",
            "\n",
            "SKILLS SUMMARY\n",
            "\n",
            "• Platforms:\n",
            "\n",
            "MongoDB, Weaviate, Pinecone, Sanity, Supabase, Firebase, Strapi, Stripe, Redux, Drizzle, Neon Js, Shopify\n",
            "\n",
            "• Soft Skills:\n",
            "\n",
            "Rapport Building, Strong Stakeholder Management, People Management, Excellent Communication\n",
            "\n",
            "MERN Stack Developer / Esspfa IT Solution\n",
            "\n",
            "July 2023 –Present\n",
            "\n",
            "◦ Collaborated with cross-functional teams to create intuitive and visually appealing user interfaces, ensuring seamless \n",
            "\n",
            "         integration with backend systems\n",
            "\n",
            "◦ Contributed to the development and maintenance of websites for diverse clients, including GoodGoblin.ai, Torquelist, \n",
            "\n",
            "         BookingTek Secondary DAO, and more, demonstrating adaptability and versatility in handling various project requirements.\n",
            "\n",
            "WORK EXPERIENCE\n",
            "\n",
            "Frontend Developer / Elearning Avenue\n",
            "\n",
            "Oct 2022 – May 2023\n",
            "\n",
            "◦ Developed and maintained scalable and performant web applications using the Next.js framework and React.js library.\n",
            "\n",
            "Instructor & Trainer / Saylani Mass IT\n",
            "\n",
            "Dec 2023 – Present\n",
            "\n",
            "◦ As an instructor of the MERN stack, I guide students through mastering MongoDB, Express.js, React, and Node.js to\n",
            "\n",
            "        build full-stack web applications.\n",
            "\n",
            "BookingTek / LINK\n",
            "\n",
            "PROJECTS\n",
            "\n",
            "◦ Technologies : Next Js ,Tailwind CSS , Typescript ,React Query \n",
            "◦ BookingTek specializes in providing digital solutions for large hotel and restaurant chains. Their primary product, TableRes, is \n",
            "\n",
            "         a mobile app that facilitates contactless ordering and payments\n",
            "\n",
            "SecondaryDAO / LINK\n",
            "\n",
            "◦ SecondaryDAO enables global investors to enter the real estate market through compliant, fractional,\n",
            "\n",
            "         tokenized ownership powered by blockchain technology.\n",
            "\n",
            "JK-SaaS Chatbot (RAG)\n",
            "\n",
            "◦  Key role in developing the backend for *JK-SaaS*, a chatbot platform utilizing Retrieval-Augmented Generation (RAG) for\n",
            "         SaaS applications. Technologies Used: Python, FastAPI, Weaviate (Vector Database)  Implemented API endpoints for eﬃcient\n",
            "         data retrieval and response generation, ensuring optimal performance and scalability for the chatbot functionalities.\n",
            "\n",
            "Torquelist / LINK\n",
            "\n",
            "◦  TorqueList is an online platform for buying and selling automotive parts and accessories. I developed both\n",
            "\n",
            "          the front end using React.js and the back end with Node.js and Express.js, utilizing MongoDB for data management,\n",
            "          ensuring seamless integration and cloud deployment.\n",
            "\n",
            "Web3 / BLOCKCHAIN PROJECTS\n",
            "\n",
            "◦ Technologies Used: Solidity, Ethereum, Chainlink, AggregatorV3Interface, Smart Contracts, Foundry \n",
            "         Created a smart contract in Solidity on the Foundry framework for a *FundMe* project on the Ethereum\n",
            "         blockchain, with comprehensive testing to ensure secure and transparent functionality.\n",
            "\n",
            "◦ Key role in creating a token marketplace using ERC20 standards in Solidity. Developed smart contracts to facilitate\n",
            "\n",
            "         secure token transactions and marketplace functionalities on the Ethereum blockchain.  Ensured robust security\n",
            "         measures and eﬃcient token management for a seamless user experience.\n",
            "\n",
            "◦ I developed a decentralized voting system ensuring transparency and security with features like voter and candidate\n",
            "\n",
            "         registration, secure voting, voting period management, and result announcement. Future enhancements include\n",
            "         optimizing gas fees and integrating a dApp for a seamless user experience.\n",
            "\n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qO5hHqnpsIg"
      },
      "outputs": [],
      "source": [
        "# import sys , fitz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHKQp7vtpsEV"
      },
      "outputs": [],
      "source": [
        "# fname = '/content/CV-Parsing-using-Spacy-3/data/test/Muhammad Raza Resume (1).pdf'\n",
        "# doc = fitz.open(fname)\n",
        "# text = \"\"\n",
        "# for page in doc:\n",
        "  # text = text + str(page.get_text())\n",
        "# doc.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjIxwf1YpsCy"
      },
      "outputs": [],
      "source": [
        "# text = text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zy1-dVU8pr-3"
      },
      "outputs": [],
      "source": [
        "# txt = \" \".join(text.split('\\n'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvQw2UishtH0"
      },
      "outputs": [],
      "source": [
        "# print(txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7d36gGPpr9h"
      },
      "outputs": [],
      "source": [
        "# doc = nlp(text)\n",
        "# for ent in doc.ents:\n",
        "  # print(ent.text, '---->' , ent.label_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lD2teLSpprzD"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/output.zip /content/output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzQ1mwz6YIwP"
      },
      "source": [
        "---\n",
        "<h4>For Reference:</h4>\n",
        "<a href='https://github.com/laxmimerit/CV-Parsing-using-Spacy-3.git'>CV-Parsing-using-Spacy-3\n",
        "</a><br>\n",
        "<a href='https://github.com/yashlikescode/spacyResumeParcer.git'>spacyResumeParcer</a>\n",
        "<hr>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}